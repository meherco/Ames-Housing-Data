{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exploratory Data Analysis of the Ames Housing Data\n",
    "\n",
    "---\n",
    "\n",
    "This project uses the [Ames housing data recently made available on kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "house = pd.read_csv('./housing.csv')\n",
    "house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5389</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1347</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20781</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11070</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "      <td>171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>370</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>1422</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4043</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "730    731         120       RL         39.0     5389   Pave   NaN      IR1   \n",
       "1346  1347          20       RL          NaN    20781   Pave   NaN      IR2   \n",
       "137    138          90       RL         82.0    11070   Pave   NaN      Reg   \n",
       "369    370          20       RL          NaN     9830   Pave   NaN      IR1   \n",
       "1421  1422         120       RL         53.0     4043   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature  \\\n",
       "730          Lvl    AllPub    ...            0    NaN   NaN         NaN   \n",
       "1346         Lvl    AllPub    ...            0    NaN   NaN         NaN   \n",
       "137          Lvl    AllPub    ...            0    NaN   NaN         NaN   \n",
       "369          Lvl    AllPub    ...            0    NaN   NaN         NaN   \n",
       "1421         Lvl    AllPub    ...            0    NaN   NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "730        0      3   2010        WD         Normal     236500  \n",
       "1346       0      6   2006        WD         Normal     262500  \n",
       "137        0      7   2006        WD         Family     171000  \n",
       "369        0      3   2010        WD         Normal     162000  \n",
       "1421       0      7   2010        WD         Normal     127500  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = (house['MSZoning'] == 'RH') | (house['MSZoning'] == 'RL') \\\n",
    "| (house['MSZoning'] == 'RP') | (house['MSZoning'] == 'RM')\\\n",
    "| (house['MSZoning'] == 'FV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house = house[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house.drop(labels=['Id'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three of the features that are continuous variables contain NaN values that must be edited. This section looks at the distribution of values amongst these features to see if replacing them with some descriptive statistic (i.e. the mean, mode) will make some sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# house.isnull().sum()\n",
    "plt.figure(figsize=(4,4))\n",
    "house['LotFrontage'].hist()\n",
    "plt.figure(figsize=(4,4))\n",
    "house['MasVnrArea'].hist()\n",
    "plt.figure(figsize=(4,4))\n",
    "house['GarageYrBlt'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of data is skewed for the features in question -- It therefore makes sense to replace the NaN values in these cases with the Mode of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house['LotFrontage'].fillna(house['LotFrontage'].mode()[0],inplace=True)\n",
    "house['MasVnrArea'].fillna(house['MasVnrArea'].mode()[0],inplace=True)\n",
    "house['GarageYrBlt'].fillna(house['GarageYrBlt'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Estimating the value of homes from fixed characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "Your superiors have outlined this year's strategy for the company:\n",
    "1. Develop an algorithm to reliably estimate the value of residential houses based on *fixed* characteristics.\n",
    "2. Identify characteristics of houses that the company can cost-effectively change/renovate with their construction team.\n",
    "3. Evaluate the mean dollar value of different renovations.\n",
    "\n",
    "Then we can use that to buy houses that are likely to sell for more than the cost of the purchase plus renovations.\n",
    "\n",
    "Your first job is to tackle #1. You have a dataset of housing sale data with a huge amount of features identifying different aspects of the house. The full description of the data features can be found in a separate file:\n",
    "\n",
    "    housing.csv\n",
    "    data_description.txt\n",
    "    \n",
    "You need to build a reliable estimator for the price of the house given characteristics of the house that cannot be renovated. Some examples include:\n",
    "- The neighborhood\n",
    "- Square feet\n",
    "- Bedrooms, bathrooms\n",
    "- Basement and garage space\n",
    "\n",
    "and many more. \n",
    "\n",
    "Some examples of things that **ARE renovate-able:**\n",
    "- Roof and exterior features\n",
    "- \"Quality\" metrics, such as kitchen quality\n",
    "- \"Condition\" metrics, such as condition of garage\n",
    "- Heating and electrical components\n",
    "\n",
    "and generally anything you deem can be modified without having to undergo major construction on the house.\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Perform any cleaning, feature engineering, and EDA you deem necessary.\n",
    "- Be sure to remove any houses that are not residential from the dataset.\n",
    "- Identify **fixed** features that can predict price.\n",
    "- Train a model on pre-2010 data and evaluate its performance on the 2010 houses.\n",
    "- Characterize your model. How well does it perform? What are the best estimates of price?\n",
    "\n",
    "> **Note:** The EDA and feature engineering component to this project is not trivial! Be sure to always think critically and creatively. Justify your actions! Use the data description file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that are classified FIXED (Not-Renovate-able):\n",
    "MSSubClass\n",
    "MSZoning\n",
    "LotFrontage\n",
    "LotArea\n",
    "Street\n",
    "Alley\n",
    "LotShape\n",
    "LandContour\n",
    "Utilities\n",
    "LotConfig\n",
    "LandSlope\n",
    "Neighborhood\n",
    "Condition1\n",
    "Condition2\n",
    "BldgType\n",
    "HouseStyle\n",
    "YearBuilt\n",
    "YearRemodAdd\n",
    "Foundation\n",
    "BsmtQual\n",
    "BsmtCond\n",
    "BsmtExposure\n",
    "BsmtFinType1\n",
    "BsmtFinSF1\n",
    "BsmtFinType2\n",
    "BsmtFinSF2\n",
    "BsmtUnfSF\n",
    "TotalBsmtSF\n",
    "1stFlrSF\n",
    "2ndFlrSF\n",
    "LowQualFinSF\n",
    "GrLivArea\n",
    "BsmtFullBath\n",
    "BsmtHalfBath\n",
    "FullBath\n",
    "HalfBath\n",
    "Bedroom\n",
    "Kitchen\n",
    "TotRmsAbvGrd\n",
    "Functional\n",
    "Fireplaces\n",
    "GarageType\n",
    "GarageYrBlt\n",
    "GarageCars\n",
    "GarageArea\n",
    "WoodDeckSF\n",
    "OpenPorchSF\n",
    "EnclosedPorch\n",
    "3SsnPorch\n",
    "ScreenPorch\n",
    "PoolArea\n",
    "MiscFeature \n",
    "MiscVal\n",
    "YrSold\n",
    "SaleType\n",
    "SaleCondition\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 -- Perform cleaning, feature engineering, and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "house = pd.read_csv('./housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 2 -- Filter out the non-residential homes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask to filter out residential homes from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = (house['MSZoning'] == 'RH') | (house['MSZoning'] == 'RL') \\\n",
    "| (house['MSZoning'] == 'RP') | (house['MSZoning'] == 'RM')\\\n",
    "| (house['MSZoning'] == 'FV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house = house[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house.drop(labels=['Id'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three of the features that are continuous variables contain NaN values that must be edited. This section looks at the distribution of values amongst these features to see if replacing them with some descriptive statistic (i.e. the mean, mode) will make some sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house.isnull().sum()\n",
    "plt.figure(figsize=(4,4))\n",
    "house['LotFrontage'].hist()\n",
    "plt.figure(figsize=(4,4))\n",
    "house['MasVnrArea'].hist()\n",
    "plt.figure(figsize=(4,4))\n",
    "house['GarageYrBlt'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of data is skewed for the features in question -- It therefore makes sense to replace the NaN values in these cases with the Mode of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house['LotFrontage'].fillna(house['LotFrontage'].mode()[0],inplace=True)\n",
    "house['MasVnrArea'].fillna(house['MasVnrArea'].mode()[0],inplace=True)\n",
    "house['GarageYrBlt'].fillna(house['GarageYrBlt'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Identify 'fixed' features that can predict house price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_features = ['MSSubClass','MSZoning','LotFrontage','LotArea','Street','Alley','LotShape',\n",
    "                  'LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1',\n",
    "                  'Condition2','BldgType','HouseStyle','YearBuilt','MasVnrArea','Foundation',\n",
    "                  'BsmtCond','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\n",
    "                  'GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n",
    "                  'KitchenAbvGr','TotRmsAbvGrd','Functional','Fireplaces','GarageType','GarageYrBlt',\n",
    "                  'GarageCars','GarageArea','PavedDrive','WoodDeckSF','OpenPorchSF','EnclosedPorch',\n",
    "                  '3SsnPorch','ScreenPorch','PoolArea','MiscFeature','MiscVal','MoSold','YrSold',\n",
    "                  'SaleType','SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the renovatable features\n",
    "renovatable_features = []\n",
    "for cols in house.columns:\n",
    "    if cols not in fixed_features:\n",
    "        renovatable_features.append(cols)\n",
    "    # Ensure YrSold added to renovatables\n",
    "    if cols == 'YrSold':\n",
    "        renovatable_features.append(cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_fixed = pd.DataFrame(house[fixed_features])\n",
    "house_fixed['SalePrice'] = house['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adds Variables that should change type to categorical\n",
    "categorical_cols = []\n",
    "numeric_cols = []\n",
    "for feature in house_fixed.columns:\n",
    "    if house_fixed[feature].dtype == 'O':\n",
    "        categorical_cols.append(feature)\n",
    "        house_fixed[feature] = house_fixed[feature].astype('category')\n",
    "    elif feature == 'MSSubClass':\n",
    "        categorical_cols.append(feature)\n",
    "        house_fixed[feature] = house_fixed[feature].astype('category')\n",
    "    else:\n",
    "        numeric_cols.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dummies on categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_fixed = pd.get_dummies(data=house_fixed,columns=categorical_cols, dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 4 -- Train a model on pre-2010 data and evaluate its performance on the 2010 houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA \n",
    "A principal component analysis was conducted on the data as a form of feature engineering. The goal of this section was to calculate the first few components of the data, and then include them as additional features before fitting the model. This was inspired by the medium article that was shared by the instructors. An important note to using PCA is that YOU MUST FIRST SCALE THE DATA. Initially I performed PCA on unscaled data and resulted in having only one significant principal component. Having only one component explain the majority of the variance is a good indicator that data may not be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sc = scaler.fit_transform(house_fixed[numeric_cols].drop('SalePrice',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca.fit(X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc_df = pd.DataFrame(pca.transform(house_fixed[numeric_cols].drop('SalePrice',axis=1)),\n",
    "             columns=['PC_{}'.format(num) for num in range(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the Principal components to the original scaled DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_fixed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_fixed_final = pd.concat([house_fixed, pc_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_fixed_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate only if skipping PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#house_fixed_final = house_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test based on the Year Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_2010_mask = house_fixed['YrSold'] == 2010\n",
    "\n",
    "house_fixed_train = house_fixed_final[~year_2010_mask]\n",
    "house_fixed_test = house_fixed_final[year_2010_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_fixed_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_fixed_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = house_fixed_train.drop('SalePrice',axis=1)\n",
    "yy_train = house_fixed_train['SalePrice']\n",
    "\n",
    "X_test = house_fixed_test.drop('SalePrice',axis=1)\n",
    "yy_test = house_fixed_test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features TRAINING set shape: {}'.format(X_train.shape))\n",
    "print('Target TRAINING set shape: {}'.format(yy_train.shape))\n",
    "print('Features TEST set shape: {}'.format(X_test.shape))\n",
    "print('Target TEST set shape: {}'.format(yy_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and test a couple models -- use Lasso, Elastic, RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LassoCV, SGDRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression, RFE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc, make_scorer, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Final Model --- RFE\n",
    "This model was selected going forward for Problem 2. The final pipeline is outlined in the diagram below. The data is scaled with StandardScaler and the number of features selected for the model was trimmed to the most important 150 features using the Recursive Feature Elimination transformer. Finally, the data is fit using a Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: load model from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_rfe_pipe = joblib.load('fixed_random_forrest_regressor.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfe_pipe = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('feature_selection', RFE(estimator=RandomForestRegressor()) ),\n",
    "#     ('regressor', RandomForestRegressor())\n",
    "# ])\n",
    "\n",
    "# rfe_params = {\n",
    "#     'feature_selection__estimator': [RandomForestRegressor()],\n",
    "#     'feature_selection__n_features_to_select': [150],\n",
    "#     'regressor__n_estimators': [300],\n",
    "#     'regressor__max_features':['log2'],\n",
    "#     'regressor__max_depth':[35]\n",
    "# }\n",
    "\n",
    "# gs_rfe_pipe = GridSearchCV(rfe_pipe,\n",
    "#                            param_grid=rfe_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=1)\n",
    "\n",
    "# gs_rfe_pipe.fit(X_train, yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_rfe_pipe.best_params_)\n",
    "print(gs_rfe_pipe.score(X_train, yy_train))\n",
    "print(gs_rfe_pipe.score(X_test,yy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is serialized below as a Python pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#joblib.dump(gs_rfe_pipe, 'fixed_random_forrest_regressor.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models were explored to see what would be the best predictor of sales price given a home's fixed features. The following blocks of code explored different regression models and feature selection transformers, however, these were not ultimately selected, but are here as a reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Reference ONLY\n",
    "________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1A -- SGD Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtsgd_pipe = Pipeline([\n",
    "#     ('skb', SelectKBest(score_func=f_regression)),\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('sfm', SelectFromModel( estimator=ElasticNet() ) ),\n",
    "#     ('clf', SGDRegressor())\n",
    "# ])\n",
    "\n",
    "# dtsgd_params = {\n",
    "# #     'skb__k':[60,70],\n",
    "#     'skb__k': [72, 75, 77],\n",
    "#     'sfm__estimator':[ElasticNet(alpha=a, l1_ratio=l) for a in np.logspace(-4,-3,5) for l in np.linspace(.1,.9,10)],\n",
    "# #     'sfm__estimator':[Lasso(alpha=a) for a in np.logspace(-6,-5,5)]\n",
    "# #     'clf__max_depth': [71, 72, 73],\n",
    "# #     'clf__max_depth':[35,40,45]\n",
    "#     'clf__penalty': ['l1', 'l2']\n",
    "    \n",
    "# }\n",
    "\n",
    "# gs_dtsgd_pipe = GridSearchCV(dtsgd_pipe,\n",
    "#                            param_grid=dtsgd_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=0)\n",
    "\n",
    "# gs_dtsgd_pipe.fit(X_train, yy_train)\n",
    "\n",
    "# gs_dtsgd_pipe.best_params_\n",
    "\n",
    "# gs_dtsgd_pipe.score(X_train, yy_train)\n",
    "\n",
    "# gs_dtsgd_pipe.score(X_test,yy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 -- RandomForest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import Lasso, ElasticNet, SGDRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# dtr_pipe = Pipeline([\n",
    "#     ('skb', SelectKBest(score_func=f_regression)),\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('sfm', SelectFromModel(estimator=ElasticNet())),\n",
    "#     ('clf', RandomForestRegressor(n_jobs=-1))\n",
    "# ])\n",
    "\n",
    "# dtr_params = {\n",
    "# #     'skb__k':[60,70],\n",
    "#     'skb__k': [72, 75, 77],\n",
    "# #     'sfm__estimator':[ElasticNet(alpha=a, l1_ratio=l) for a in np.logspace(-4,-3,5) for l in np.linspace(.1,.9,10)],\n",
    "#     'sfm__estimator':[Lasso(alpha=a) for a in np.logspace(-6,-5,5)],\n",
    "#     'clf__max_depth': [71, 72, 73],\n",
    "# #     'clf__max_depth':[35,40,45]\n",
    "    \n",
    "# }\n",
    "\n",
    "# gs_dtr_pipe = GridSearchCV(dtr_pipe,\n",
    "#                            param_grid=dtr_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=0)\n",
    "\n",
    "# gs_dtr_pipe.fit(X_train, yy_train)\n",
    "\n",
    "# gs_dtr_pipe.best_params_\n",
    "\n",
    "# gs_dtr_pipe.score(X_train, yy_train)\n",
    "\n",
    "# gs_dtr_pipe.score(X_test,yy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 -------- Linear Regression con L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtl_pipe = Pipeline([\n",
    "#     ('skb', SelectKBest(score_func=f_regression)),\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('sfm', SelectFromModel(estimator=Lasso())),\n",
    "#     ('lr', Lasso())\n",
    "# ])\n",
    "# dtl_params = {\n",
    "#     'skb__k':[50, 51, 52],\n",
    "#     'sfm__estimator':[Lasso(), ElasticNet()],\n",
    "#     'lr__alpha': np.logspace(-4,2,9)\n",
    "    \n",
    "# }\n",
    "\n",
    "# gs_dtl_pipe = GridSearchCV(dtl_pipe,\n",
    "#                            param_grid=dtl_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=1)\n",
    "\n",
    "# gs_dtl_pipe.fit(X_train, yy_train)\n",
    "\n",
    "# gs_dtl_pipe.score(X_train,yy_train)\n",
    "\n",
    "# gs_dtl_pipe.score(X_test,yy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference End\n",
    "________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Characterize your model. How well does it perform? What are the best estimates of price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the scores from the training and test sets above, I'm confident that the model is accurately predicting home sales price. The trained model ended up with an accuracy close to 98%, while the test score was closer to 87%. It can be argued that the model is slightly overfitting the data because of it's near-perfect training score, but I'm not too concerned at the moment considering that the test score for predicting 2010 home sale prices was still relatively good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps will show the most important features that were determined from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the sum of the feature importances add to 1, indicating that each feature importance represents a percentage of the total sum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(gs_rfe_pipe.best_estimator_.named_steps['regressor'].feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the 150 features that were selected from the Recursive Feature Elimination Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_mask = pd.Series(gs_rfe_pipe.best_estimator_.named_steps['feature_selection'].support_)\n",
    "feat=X_train.columns[feat_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_feat_imps = gs_rfe_pipe.best_estimator_.named_steps['regressor'].feature_importances_\n",
    "# col_names = [\"col_{}\".format(i) for i in range(1,20)]\n",
    "col_names = X_train.columns[feat_mask]\n",
    "feats_df = pd.DataFrame(list(zip(col_names, xgb_feat_imps)), columns= ['col_name','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_20_feats = feats_df.sort_values('importance',ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(top_20_feats.shape[0]), top_20_feats['importance'], align='center')\n",
    "ax.set_yticks(np.arange(top_20_feats.shape[0]))\n",
    "ax.set_yticklabels(top_20_feats['col_name'])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_ylabel('Top 20 Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the top 20 features most important to predicting the sales price of a home. By observing the first few indicators we can see there is a trend for the type of features that are important in prediction. Features like above ground living area ('GrLivArea'), garage area, total basement area, and first floor area are all metrics that evaluate the home space in square-feet. This is something that intuitively makes sense -- the larger a home is, the more valuable it is likely to be. More surprisingly, we can see that the principal components that were feature engineered appear in the top twenty. PC1 comes in second, while PC3 and PC2 also make the list. Although we can only guess what quality is really being measured by these features, it is validating to see that the principal components calculated were capturing the data's highest explained variance and therefore are likely candidates for the creation of predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Determine any value of *changeable* property characteristics unexplained by the *fixed* ones.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you have a model that estimates the price of a house based on its static characteristics, we can move forward with part 2 and 3 of the plan: what are the costs/benefits of quality, condition, and renovations?\n",
    "\n",
    "There are two specific requirements for these estimates:\n",
    "1. The estimates of effects must be in terms of dollars added or subtracted from the house value. \n",
    "2. The effects must be on the variance in price remaining from the first model.\n",
    "\n",
    "The residuals from the first model (training and testing) represent the variance in price unexplained by the fixed characteristics. Of that variance in price remaining, how much of it can be explained by the easy-to-change aspects of the property?\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Evaluate the effect in dollars of the renovate-able features. \n",
    "- How would your company use this second model and its coefficients to determine whether they should buy a property or not? Explain how the company can use the two models you have built to determine if they can make money. \n",
    "- Investigate how much of the variance in price remaining is explained by these features.\n",
    "- Do you trust your model? Should it be used to evaluate which properties to buy and fix up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Evaluate the effect in dollars of the renovate-able features\n",
    "For this question, I create a model using the renovate-able features that were defined earlier in this notebook to predict the residuals calculated from the model in Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "residuals_train = yy_train - gs_rfe_pipe.predict(X_train)\n",
    "residuals_test = yy_test - gs_rfe_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_renovatable = pd.DataFrame(house[renovatable_features])\n",
    "house_renovatable['SalePrice'] = house['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_renovatable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_renovatable.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adds Variables that should change type to categorical\n",
    "categorical_cols = []\n",
    "numeric_cols = []\n",
    "for feature in house_renovatable.columns:\n",
    "    if house_renovatable[feature].dtype == 'O':\n",
    "        categorical_cols.append(feature)\n",
    "        house_renovatable[feature] = house_renovatable[feature].astype('category')\n",
    "    else:\n",
    "        numeric_cols.append(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_renovatable.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_renovatable = pd.get_dummies(data=house_renovatable, columns=categorical_cols, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_renovatable.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_2010_mask = house_renovatable['YrSold'] == 2010\n",
    "\n",
    "house_renovatable_train = house_renovatable[~year_2010_mask]\n",
    "house_renovatable_test = house_renovatable[year_2010_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = house_renovatable_train.drop('SalePrice',axis=1)\n",
    "X_test = house_renovatable_test.drop('SalePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features TRAINING set shape: {}'.format(X_train.shape))\n",
    "print('Target TRAINING set shape: {}'.format(residuals_train.shape))\n",
    "print('Features TEST set shape: {}'.format(X_test.shape))\n",
    "print('Target TEST set shape: {}'.format(residuals_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model Using Same Pipeline from Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_renovate_pipe = joblib.load('renovate_random_forrest_regressor.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# renovate_pipe = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('feature_selection', RFE(estimator=RandomForestRegressor()) ),\n",
    "#     ('regressor', RandomForestRegressor())\n",
    "# ])\n",
    "\n",
    "# renovate_params = {\n",
    "#     'feature_selection__estimator': [RandomForestRegressor()],\n",
    "#     'feature_selection__n_features_to_select': [150],\n",
    "#     'regressor__n_estimators': [300],\n",
    "#     'regressor__max_features':['log2','auto'],\n",
    "#     'regressor__max_depth':[60]\n",
    "# }\n",
    "\n",
    "# gs_renovate_pipe = GridSearchCV(renovate_pipe,\n",
    "#                            param_grid=renovate_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=1)\n",
    "\n",
    "# gs_renovate_pipe.fit(X_train, yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_renovate_pipe.best_params_)\n",
    "print(gs_renovate_pipe.score(X_train, yy_train))\n",
    "print(gs_renovate_pipe.score(X_test, yy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is serialized below as a Python pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joblib.dump(gs_renovate_pipe, 'renovate_random_forrest_regressor.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Reference ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renovate_pipe = Pipeline([\n",
    "#     ('skb', SelectKBest(score_func=f_regression)),\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('sfm', SelectFromModel( estimator=ElasticNet() ) ),\n",
    "#     ('clf', SGDRegressor())\n",
    "# ])\n",
    "\n",
    "# renovate_params = {\n",
    "# #     'skb__k':[60,70],\n",
    "#     'skb__k': [72, 75, 77],\n",
    "#     'sfm__estimator':[ElasticNet(alpha=a, l1_ratio=l) for a in np.logspace(-4,-3,5) for l in np.linspace(.1,.9,10)],\n",
    "# #     'sfm__estimator':[Lasso(alpha=a) for a in np.logspace(-6,-5,5)]\n",
    "# #     'clf__max_depth': [71, 72, 73],\n",
    "# #     'clf__max_depth':[35,40,45]\n",
    "#     'clf__penalty': ['l1', 'l2']\n",
    "    \n",
    "# }\n",
    "\n",
    "# gs_renovate_pipe = GridSearchCV(renovate_pipe,\n",
    "#                            param_grid=renovate_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=0)\n",
    "\n",
    "# gs_renovate_pipe.fit(X_train, yy_train)\n",
    "\n",
    "# gs_renovate_pipe.best_params_\n",
    "\n",
    "# print(gs_renovate_pipe.score(X_train, yy_train))\n",
    "# print(gs_renovate_pipe.score(X_test, yy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtsgd_pipe = Pipeline([\n",
    "#     ('skb', SelectKBest(score_func=f_regression)),\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('sfm', SelectFromModel( estimator=ElasticNet() ) ),\n",
    "#     ('clf', SGDRegressor())\n",
    "# ])\n",
    "\n",
    "# dtsgd_params = {\n",
    "# #     'skb__k':[60,70],\n",
    "#     'skb__k': [72, 75, 77],\n",
    "#     'sfm__estimator':[ElasticNet(alpha=a, l1_ratio=l) for a in np.logspace(-4,-3,5) for l in np.linspace(.1,.9,10)],\n",
    "# #     'sfm__estimator':[Lasso(alpha=a) for a in np.logspace(-6,-5,5)]\n",
    "# #     'clf__max_depth': [71, 72, 73],\n",
    "# #     'clf__max_depth':[35,40,45]\n",
    "#     'clf__penalty': ['l1', 'l2']\n",
    "    \n",
    "# }\n",
    "\n",
    "# gs_dtsgd_pipe = GridSearchCV(dtsgd_pipe,\n",
    "#                            param_grid=dtsgd_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=0)\n",
    "\n",
    "# gs_dtsgd_pipe.fit(X_train, yy_train)\n",
    "# gs_dtsgd_pipe.best_params_\n",
    "\n",
    "\n",
    "# print(gs_dtsgd_pipe.score(X_train, yy_train))\n",
    "# print(gs_dtsgd_pipe.score(X_test,yy_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How would your company use this second model and its coefficients to determine whether they should buy a property or not? Explain how the company can use the two models you have build to determine if they can make money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model that was created predicts the sales price of a home based on the features that were deemed 'fixed'. In the second model, the sales price is predicted from the 'renovatable' parts of the home. The combination of these two models can be used by the company to determine if buying a property would turn over profit. By using the first model, the company can estimate the value of a home, let's say for example \\$100,000. This would be the price that the company would pay to buy a home. The second model can then be used to estimate the sales price of that same home after a series of renovations take place. For example, let's say that the company invests in some renovations in the home thereby raising the quality of the bathrooms and the garage conditions. The raised conditions predict the sales price of the home to be \\$120,000. Therefore, the company could sell the home at \\$120,000. The company would then make money if the cost of the renovations did not exceed the \\$20,000 increased value of the home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Investigate how much of the variance in price remaining is explained by these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The variance in the price remaining from the first model were calculated as the residuals in an earlier step of this notebook and are plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(residuals_train)\n",
    "plt.title('Training Set Residuals')\n",
    "plt.figure()\n",
    "plt.plot(residuals_test)\n",
    "plt.title('Test Set Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(residuals_train))\n",
    "print(np.std(residuals_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals between the model from Part 1 and the data are quite substantial in some of the cases. While most of the residuals fall within \\$5000 of the actual test data, some exceed as high as $200000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Do you trust your model? Should it be used to evaluate which properties to buy and fix up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Not sure if I trust my model yet. I would like to have more time to find a better fitting model -- the test data scored 78% accuracy. I would be more comfortable to have a more accurate model in order to justify the difference in residuals from my first model. With more time, I probably could try some additional feature engineering to overcome this gap and to confidently describe the variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. What property characteristics predict an \"abnormal\" sale?\n",
    "\n",
    "---\n",
    "\n",
    "The `SaleCondition` feature indicates the circumstances of the house sale. From the data file, we can see that the possibilities are:\n",
    "\n",
    "       Normal\tNormal Sale\n",
    "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand\tAdjoining Land Purchase\n",
    "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
    "       Family\tSale between family members\n",
    "       Partial\tHome was not completed when last assessed (associated with New Homes)\n",
    "       \n",
    "One of the executives at your company has an \"in\" with higher-ups at the major regional bank. His friends at the bank have made him a proposal: if he can reliably indicate what features, if any, predict \"abnormal\" sales (foreclosures, short sales, etc.), then in return the bank will give him first dibs on the pre-auction purchase of those properties (at a dirt-cheap price).\n",
    "\n",
    "He has tasked you with determining (and adequately validating) which features of a property predict this type of sale. \n",
    "\n",
    "---\n",
    "\n",
    "**Your task:**\n",
    "1. Determine which features predict the `Abnorml` category in the `SaleCondition` feature.\n",
    "- Justify your results.\n",
    "\n",
    "This is a challenging task that tests your ability to perform classification analysis in the face of severe class imbalance. You may find that simply running a classifier on the full dataset to predict the category ends up useless: when there is bad class imbalance classifiers often tend to simply guess the majority class.\n",
    "\n",
    "It is up to you to determine how you will tackle this problem. I recommend doing some research to find out how others have dealt with the problem in the past. Make sure to justify your solution. Don't worry about it being \"the best\" solution, but be rigorous.\n",
    "\n",
    "Be sure to indicate which features are predictive (if any) and whether they are positive or negative predictors of abnormal sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Determine which features predict the 'Abnorml' category in the 'SaleCondition' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For answering this question, a new model was built. Instead of using just renovatable or fixed features, all features were included in the model. A gradient boosting model was fit to the data and the top twenty important features were identified. The following section outlines the data prepping of the original housing data in the DataFrame 'house'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adds Variables that should change type to categorical\n",
    "categorical_cols = []\n",
    "numeric_cols = []\n",
    "for feature in house.columns:\n",
    "    if house[feature].dtype == 'O':\n",
    "        categorical_cols.append(feature)\n",
    "        house[feature] = house[feature].astype('category')\n",
    "    else:\n",
    "        numeric_cols.append(feature)\n",
    "categorical_cols.remove('SaleCondition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = house.drop('SaleCondition',axis=1)\n",
    "yy_= house['SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = pd.get_dummies(X_, columns=categorical_cols, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(yy_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following encodes the target feature 'SaleCondition' such that the abnormal sales are assigned to the value 1, and all others are assinged to the value of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy_ = yy_.apply(lambda x: 1 if x == 'Abnorml' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_,yy_,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.Series(y_test)\n",
    "y_train = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create boosted model to predict the home SaleCondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-trained model from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf_pipe = joblib.load('SaleCondition_clf.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf_pipe = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('clf', xgb.XGBClassifier())\n",
    "# ])\n",
    "\n",
    "# clf_params ={\n",
    "#     'clf__max_depth':[1,3,5],\n",
    "#     'clf__learning_rate':[.1,.5],\n",
    "#     'clf__n_estimators':[100,250]\n",
    "# }\n",
    "\n",
    "# gs_clf_pipe = GridSearchCV(clf_pipe,\n",
    "#                            param_grid=clf_params,\n",
    "#                            cv=ShuffleSplit(n_splits=5, random_state=42),\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose=1)\n",
    "# gs_clf_pipe.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_clf_pipe.best_params_)\n",
    "print(gs_clf_pipe.score(X_train,y_train))\n",
    "print(gs_clf_pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joblib.dump(gs_clf_pipe, 'SaleCondition_clf.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to rank the feature importance and to display the top twenty features that contributed to predicting the abnormal sale condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_feat_imps = gs_clf_pipe.best_estimator_.named_steps['clf'].feature_importances_\n",
    "# col_names = [\"col_{}\".format(i) for i in range(1,20)]\n",
    "col_names = X_.columns\n",
    "feats_df = pd.DataFrame(list(zip(col_names, xgb_feat_imps)), columns= ['col_name','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_20_feats = feats_df.sort_values('importance',ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(top_20_feats.shape[0]), top_20_feats['importance'], align='center')\n",
    "ax.set_yticks(np.arange(top_20_feats.shape[0]))\n",
    "ax.set_yticklabels(top_20_feats['col_name'])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_ylabel('Top 20 Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf_pipe.best_estimator_.named_steps['clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Justify your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was actually more simple than I thought it would be. Using a gradient-boosted model on the entire dataset, I was able to train a model that achieved 94.5% model accuracy with the training data, and 91% accuracy with the test set. IN this particular approach, no special feature engineering was done. The data was prepared such that the model only predicts if the sale was abnormal or not -- it does not give any insights to a sale condition other than abnormal. From the plot of the top 20 features above, we see that sales price was a strong indicator on the abnormality of the sale. This makes a lot of sense -- since abnormal sales probably correlated strongly with lower sales prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to instructor: There was a lot more work that I would like to have done to this notebook, but I simply ran out of time. For future work, I would plot more EDA to explore some of the features in greater detail and to give some insights into more clever ways to feature engineering. It would have been instresting to see if ONLY the PCA components were used in the model generation, if that would have yeilded higher scores. I was also inclined to explore the use of polynomial features to see if that had the same desired effect as including the PCA components that I did earlier. In general, I spent too much time on trying out different types of machine learning models that didn't yeild satisfactory scores. Will probably build on the future work I've outlined here for preparing my portfolio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
